# Letterboxd Normal Distributions

## Timeline


### Letterboxd API Closed Off Struggles
Sep 06 '23

So, as I've found before in years past, the [Letterboxd API](https://api-docs.letterboxd.com/) is [not available to the public](https://letterboxd.com/api-beta/) (yet?). So, for the data that I want, I might have to go spelunking.

As for what I am trying to get and determine, on a loose basis. I want to determine if the the average Letterboxd user has a normal distribution of their film ratings like [I do](https://letterboxd.com/hahaveryfun/). I see many that don't, so I just wanted to determine if that's odd.

Looks like my best option might be to look for a proxy service, or a pseudo-api that has just effectively written a web-scraper.

...Timelapse of about 20 minutes...

And it looks like there are some users have created a webscraper overlay on top of Letterboxd to avoid the API. One such project is [here](https://github.com/Fitzy1293/lboxd). Demo from the README looks promising and was working on first try.

### Making Sure Data is There
Sep 07 '23

That same API from before, that is basically a web scraper, has some functionality about directly pulling movies and their ratings, rather than whole reviews. This should be good. However, it seems to not return any data. Rather, the package is not returning any data, so I'm going to dig into this and see if I can see if the requests/base URLs just need to be modified.

It looks like we have liftoff! I can successfully get a user's ratings to a particular movie for their entire account history.

I even tracked down that I had accidentally marked a movie as watched that I hadn't seen yet.

Really just had to modify a string delimiter from the library that is outdated. Previously, it was this: `'data-film-slug="/film/'`, now it should be this `'data-film-slug="'`, without the `/film/` prefix to the value of the resulting HTML element attribute.

And as a note for myself tomorrow, it looks like I can get a pretty decent number of users to scrape from via the popular members lists:

https://letterboxd.com/members/popular/this/all-time/page/256/ (it only goes up to 256 pages)

There are also "This Year", "This Month", & "This Week" variants that would be useful, after deduplicating users, of course. At minimum, the All-Time pages should yield around 7680 (30*256) users alone. Granted, they are very popular users, with the 7680th user having ~1800 followers, so not very sure if it is a great sample of the "entire" platform, but it's a start.

### Tossing it all into a CSV
Sep 08 '23

Scraping web pages takes a really long time. On a rough, eyeball average, each of the 5 most popular Letterboxd users has watched in the neighborhood of 2000 movies. So if we assume they have given ratings to about at least 500 unique movies, that leaves us with about 7 page loads _per user_. Not to mention any other page loads we'll need to do other things to fetch the list of users we are pulling from.

So, after getting all the information I needed after tuning the web scraper, I have dumped all the rating data on a per user basis into a timestamped .csv file. That way I don't need to reload any data. It's a little weird because it's effectively 2D data, with there being a list of usernames, and then a list of ratings per username. So I decided to concatenate them all together with a "/" character. Take a look at an example over in this file on the project's repository [here](https://github.com/willdunk/letterboxd-normal/blob/main/data_2023-09-09_02-21-09.csv)

Going to run this once over night here with around 5000 users, and then give it a whirl at some calculations at trying to discover at how normal these rating charts really are!