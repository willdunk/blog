# Letterboxd Normal Distributions

## Timeline


### Letterboxd API Closed Off Struggles
Sep 06 '23

So, as I've found before in years past, the [Letterboxd API](https://api-docs.letterboxd.com/) is [not available to the public](https://letterboxd.com/api-beta/) (yet?). So, for the data that I want, I might have to go spelunking.

As for what I am trying to get and determine, on a loose basis. I want to determine if the the average Letterboxd user has a normal distribution of their film ratings like [I do](https://letterboxd.com/hahaveryfun/). I see many that don't, so I just wanted to determine if that's odd.

Looks like my best option might be to look for a proxy service, or a pseudo-api that has just effectively written a web-scraper.

...Timelapse of about 20 minutes...

And it looks like there are some users have created a webscraper overlay on top of Letterboxd to avoid the API. One such project is [here](https://github.com/Fitzy1293/lboxd). Demo from the README looks promising and was working on first try.

### Making Sure Data is There
Sep 07 '23

That same API from before, that is basically a web scraper, has some functionality about directly pulling movies and their ratings, rather than whole reviews. This should be good. However, it seems to not return any data. Rather, the package is not returning any data, so I'm going to dig into this and see if I can see if the requests/base URLs just need to be modified.

It looks like we have liftoff! I can successfully get a user's ratings to a particular movie for their entire account history.

I even tracked down that I had accidentally marked a movie as watched that I hadn't seen yet.

Really just had to modify a string delimiter from the library that is outdated. Previously, it was this: `'data-film-slug="/film/'`, now it should be this `'data-film-slug="'`, without the `/film/` prefix to the value of the resulting HTML element attribute.

And as a note for myself tomorrow, it looks like I can get a pretty decent number of users to scrape from via the popular members lists:

https://letterboxd.com/members/popular/this/all-time/page/256/ (it only goes up to 256 pages)

There are also "This Year", "This Month", & "This Week" variants that would be useful, after deduplicating users, of course. At minimum, the All-Time pages should yield around 7680 (30*256) users alone. Granted, they are very popular users, with the 7680th user having ~1800 followers, so not very sure if it is a great sample of the "entire" platform, but it's a start.

### Tossing it all into a CSV
Sep 08 '23

Scraping web pages takes a really long time. On a rough, eyeball average, each of the 5 most popular Letterboxd users has watched in the neighborhood of 2000 movies. So if we assume they have given ratings to about at least 500 unique movies, that leaves us with about 7 page loads _per user_. Not to mention any other page loads we'll need to do other things to fetch the list of users we are pulling from.

So, after getting all the information I needed after tuning the web scraper, I have dumped all the rating data on a per user basis into a timestamped .csv file. That way I don't need to reload any data. It's a little weird because it's effectively 2D data, with there being a list of usernames, and then a list of ratings per username. So I decided to concatenate them all together with a "/" character. Take a look at an example over in this file on the project's repository [here](https://github.com/willdunk/letterboxd-normal/blob/main/data_2023-09-09_02-21-09.csv)

Going to run this once over night here with around 5000 users, and then give it a whirl at some calculations at trying to discover at how normal these rating charts really are!

### The Critical Part
Sep 13 '23

Given that we have our data now, at least for a few accounts (I'll scrape further accounts later), we now need to compare them against a normal distribution.

So, breaking out my high school and collegiate statistics, I'll need to take each user's probability density function based on their mean and standard deviation and build that. 

Wow! So I have done a few things here based on my own profile:

1. Here's a histogram based on my own Letterboxd profile's ratings, and a normal distribution fit line laid on top based on the ratings' mean and standard deviation: 
![Histogram for hahaveryfun](https://i.imgur.com/sPRDcTL.png)

2. And then there is also a Quantile-Quantile Plot to see how far off each rating was from the normal distribution:
![Q-Q Chart for hahaveryfun](https://i.imgur.com/ydalcjA.png)

So already, very easy to really create some pretty compelling cases for a normal distribution, at least on my profile, and just an eye test. But when it comes to a [Shapiro-Wilk test](https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test), the resulting p value that the difference in my rating sample was different than a normal distribution was much higher than the standard of .05 for a significance level. So, as a result, my ratings were deemed "not normally distributed"

Given that this is not super scientific and I think that my ratings are an okay representation, I'm going to relax the alpha value here and run this again.

I've relaxed it a few times, and it's still failing. But, my p_value is close to 0. Like 3.5e-12 sort of range. I'll need to look at that. But progress is being made.

### Is the p Value Really Far Off?
Sep 14 '23

So it looks like the classic chi-squared test might be a better option for me, given the discreteness of this data. That test I remember from various statistics classes I've taken in the past. So I'll give this one a try.

I got a little engrossed in that one! Took a bit of fiddling with this and getting used to how exactly pystats and numpy works again. They really don't work exactly the way I would think they work, nor is documentation on them helpful to non-math specialized people.

It looks like, based on my new adjusted chi-squared test, that my distributions *are* normally distributed, with a p_value of 0.9996. My script right now assumes that you have rated at least one movie at each possible rating value, so I need to fix that. I also want to find someone who definitely doesn't have a normal distribution and see how this goes.

So I tried someone [here](https://letterboxd.com/jeaba/) that seems to have a semi-normal distribution, but definitely not a "bell" shape in their rating distribution. It turned up a p_value of about 0.9996 again, but slightly less than mine the more precise it became. However, it was very noticeable on a user like [this](https://letterboxd.com/gracemilly211/) where the disparity is very extreme. But even then, the p_value was still 0.807. I think I still have some tuning to do on this. It may also be just that there are relatively few categories, with only 10 possible ratings here. But the more likely option is that I am just doing this wrong.